{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9085deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import requests\n",
    "import os\n",
    "from config import config\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas_market_calendars as mcal\n",
    "from preprocessing.get_and_process_data import *\n",
    "import yahoo_fin.stock_info as si\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce169df",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '26f02b30c6137017402dcd75e2499440'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e21ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic_list = si.tickers_dow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1190d5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471bfd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mData\u001b[m\u001b[m/                                  ress3k_fundamental_final.csv\r\n",
      "README.md                              ress3k_fundamental_final_20210901.csv\r\n",
      "Russell-3000-Stock-Tickers-List.xlsx   \u001b[34mresults\u001b[m\u001b[m/\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m/                           \u001b[31mrun.sh\u001b[m\u001b[m*\r\n",
      "code-wrapper.ipynb                     russe3k_21y_stock.csv\r\n",
      "\u001b[34mconfig\u001b[m\u001b[m/                                russe3k_21y_stock_with_sector.csv\r\n",
      "conm_tic.csv                           russel3k_sector_tic_full.csv\r\n",
      "\u001b[34mfigs\u001b[m\u001b[m/                                  russel3k_tic.csv\r\n",
      "fundamental_run_model.py               russle3k_tic_sector_comn.csv\r\n",
      "main.py                                sector_tic.csv\r\n",
      "\u001b[34mmodels\u001b[m\u001b[m/                                select_top20.py\r\n",
      "\u001b[34mpreprocessing\u001b[m\u001b[m/                         stocks_weight_table20211008.csv\r\n",
      "\u001b[34mraw-data\u001b[m\u001b[m/                              \u001b[34mtables_by_secotr_and_riskLevel\u001b[m\u001b[m/\r\n",
      "\u001b[34mraw_data\u001b[m\u001b[m/                              tic_cnt.csv\r\n",
      "requirements.txt                       top20_risk_sector_stocks.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311f5c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_file = \"raw-data/dow30_km_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6239f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_metrics(tic,limit=100):\n",
    "\n",
    "    api_key = config.api_key\n",
    "    v3_string = 'https://financialmodelingprep.com/api/v3'\n",
    "   \n",
    "    try:\n",
    "        target_url = f'{v3_string}/key-metrics/{tic}?period=quarter&limit={limit}&apikey={api_key}'\n",
    "        #print(target_url)\n",
    "        res = requests.get(target_url).json()\n",
    "#             #res = res.get('historical')\n",
    "#             return pd.DataFrame(res).drop(columns = \"label\")\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'get_price failed for {tic}')\n",
    "        pass\n",
    "    \n",
    "def get_tics_key_metrics(km_file, tic_list):        \n",
    "    kms = []\n",
    "    for tic in tic_list:\n",
    "        one_km_raw = get_key_metrics(tic,limit=100)\n",
    "        one_tic_km_raw = pd.DataFrame(one_km_raw)\n",
    "        kms.append(one_tic_km_raw)\n",
    "    if len(kms)>0:\n",
    "        km_df = pd.concat(kms)\n",
    "    else:\n",
    "        print(\"[Error] Encountering error while retrieving key metrics: 0 key metric is retrieved\")\n",
    "        return\n",
    "    km_df = km_df.drop_duplicates(subset=['date','symbol']).sort_values(['symbol','date']).reset_index(drop=True)\n",
    "    km_df.to_csv(km_file, index=False)\n",
    "    return km_df\n",
    "\n",
    "def get_income_statements(tic,limit=100):\n",
    "    api_key = config.api_key\n",
    "    v3_string = 'https://financialmodelingprep.com/api/v3'\n",
    "    try:\n",
    "        target_url = f'{v3_string}/income-statement/{tic}?period=quarter&limit={limit}&apikey={api_key}'\n",
    "        #print(target_url)\n",
    "        res = requests.get(target_url).json()\n",
    "        return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'get_price failed for {tic}')\n",
    "        pass \n",
    "def get_tics_incom_states(fa_file,tic_list):\n",
    "    fas = []\n",
    "    for tic in tic_list:\n",
    "        one_fa_raw = get_income_statements(tic,limit=100)\n",
    "        one_tic_fa_raw = pd.DataFrame(one_fa_raw)\n",
    "        fas.append(one_tic_fa_raw)\n",
    "    if len(fas)>0:\n",
    "        fa_df = pd.concat(fas)\n",
    "    else:\n",
    "        print(\"[Error] Encountering error while retrieving income statements: 0 income statement is retrieved\")\n",
    "        return\n",
    "    fa_df = fa_df.drop_duplicates(subset=['date','symbol']).sort_values(['symbol','date']).reset_index(drop=True)\n",
    "    fa_df.to_csv(fa_file, index=False)\n",
    "    return fa_df\n",
    "\n",
    "def get_stocks_data(stock_file,tic_list,lookback_days):\n",
    "    def pull_data_by_tic(ticker, start, end):\n",
    "        df_ticker = yf.download(ticker,start,end, progress=False)\n",
    "        df_ticker = df_ticker.reset_index()\n",
    "        df_ticker['tic'] = ticker\n",
    "        return df_ticker\n",
    "    end = dt.datetime.now()\n",
    "    exist_file = os.path.exists(stock_file)\n",
    "    stocks = []\n",
    "    for tic in tic_list:\n",
    "        df_tic = yf.download(tic,  end + dt.timedelta(days=-lookback_days), end, progress=False)\n",
    "        df_tic = df_tic.reset_index()\n",
    "        df_tic['tic'] = tic\n",
    "        stocks.append(df_tic)\n",
    "    if len(stocks) > 0:\n",
    "        df = pd.concat(stocks)\n",
    "        df = df.drop_duplicates(subset=['tic','Date'])\n",
    "        df.to_csv(stock_file, index=False)\n",
    "        return df\n",
    "    print(\"[Error] Encountering error while retrieving stock data: no stock data are retrieved\")\n",
    "    return None\n",
    "\n",
    "def processing_raw_data(km_df,fa_df,stocks_df,sector_tic, gvkey_conm_unique, final_file_prefix):\n",
    "\n",
    "    df1 = km_df[['symbol','date','period','roe','peRatio','priceToSalesRatio','evToSales','pbRatio',\n",
    "                        'pocfratio','currentRatio','enterpriseValueOverEBITDA','evToOperatingCashFlow',\n",
    "                        'debtToAssets','netDebtToEBITDA','debtToEquity','payablesTurnover','daysSalesOutstanding',\n",
    "                        'daysPayablesOutstanding']]\n",
    "    df1 = df1.rename(columns = {'symbol':'tic','period':'quarter','roe':'X4_ROE','peRatio':'X5_PE',\n",
    "                                'priceToSalesRatio':'X6_PS','evToSales':'X9_OM','pbRatio':'X10_PB','pocfratio':'X11_PCFO',\n",
    "                                'currentRatio':'X12_CR','enterpriseValueOverEBITDA':'X13_EM','evToOperatingCashFlow':'X14_EVCFO',\n",
    "                                'debtToAssets':'X15_LTDTA','netDebtToEBITDA':'X16_WCR','debtToEquity':'X17_DE','payablesTurnover':'X18_QR',\n",
    "                                'daysSalesOutstanding':'X19_DSI','daysPayablesOutstanding':'X20_DPO'})\n",
    "    df1['datadate'] = pd.to_datetime(df1['date'])\n",
    "    df1['datadate'] = df1['datadate'].apply(lambda x: dt.datetime.strftime(x,'%Y%m%d'))\n",
    "    df1 = df1.set_index(['datadate','tic'])\n",
    "    \n",
    "    \n",
    "    df2 = fa_df[['date','symbol','period','revenue','eps','operatingIncomeRatio',\n",
    "                            'netIncomeRatio','grossProfitRatio']]\n",
    "    df2 = df2.rename(columns={'symbol':'tic','revenue':'X1_REVGH','eps':'X2_EPS','operatingIncomeRatio':'X3_ROA',\n",
    "                              'netIncomeRatio':'X7_NPM','grossProfitRatio':'X8_GPM'})\n",
    "    df2['datadate2'] = pd.to_datetime(df2['date'])\n",
    "    df2['datadate'] = df2['datadate2'].apply(lambda x: dt.datetime.strftime(x,'%Y%m%d'))\n",
    "    df2 = df2.set_index(['datadate','tic'])                                                \n",
    "\n",
    "    df = pd.merge(df1,df2.drop('date',axis=1), on=(['datadate','tic']), how='inner')\n",
    "    \n",
    "    df = df.reset_index()\n",
    "    df['fyearq'] = df['datadate2'].apply(lambda x: dt.datetime.strftime(x,'%Y'))\n",
    "    df['datacqtr'] = df['datadate2'].apply(get_quarters)\n",
    "    df['datafqtr'] = df['fyearq']+ df['quarter']\n",
    "    df['tradedate'] = df['datadate2'].apply(get_trade_date)\n",
    "    df['fqtr'] = df['datadate2'].apply(get_quarter_num)                                                \n",
    "    \n",
    "    \n",
    "    df_gvkey = df.join(gvkey_conm_unique, on='tic',how='left')\n",
    "                                                     \n",
    "    fakm_final = df_gvkey[['tic','datadate','tradedate','fyearq','fqtr','conm','datacqtr','datafqtr',\n",
    "                         'X1_REVGH','X2_EPS','X3_ROA','X4_ROE','X5_PE','X6_PS','X7_NPM','X8_GPM','X9_OM','X10_PB',\n",
    "                         'X11_PCFO','X12_CR','X13_EM','X14_EVCFO','X15_LTDTA','X16_WCR','X17_DE','X18_QR','X19_DSI',\n",
    "                         'X20_DPO']] \n",
    "    fc = ['X1_REVGH','X2_EPS','X3_ROA','X4_ROE','X5_PE','X6_PS','X7_NPM','X8_GPM','X9_OM','X10_PB',\n",
    "                         'X11_PCFO','X12_CR','X13_EM','X14_EVCFO','X15_LTDTA','X16_WCR','X17_DE','X18_QR','X19_DSI',\n",
    "                         'X20_DPO']\n",
    "    fakm_final.to_csv('fakm_final.csv')\n",
    "    fakm_final['month'] = fakm_final['tradedate'].astype(int)//100\n",
    " \n",
    "    # combine with y_return from stock_df   \n",
    "\n",
    "    stocks_df['Date'] = pd.to_datetime(stocks_df['Date'])\n",
    "    stocks_df['datadate'] = pd.to_datetime(stocks_df['Date']).apply(lambda x: dt.datetime.strftime(x,'%Y%m%d'))\n",
    "    stocks_df['datadate'] = stocks_df['datadate'].astype(int)\n",
    "\n",
    "    nyse = mcal.get_calendar('NYSE')\n",
    "    trade_dates = nyse.schedule(start_date=stocks_df['Date'].min()+dt.timedelta(days=-60), end_date=stocks_df['Date'].max()+dt.timedelta(days=210))\n",
    "    trade_dates_list = list(trade_dates.index)\n",
    "    \n",
    "    trading_dates = []\n",
    "    for i in range(len(trade_dates_list)):\n",
    "        date = trade_dates_list[i].strftime('%Y%m%d')\n",
    "        trading_dates.append(int(date))\n",
    "    \n",
    "    #trading_dates_set = set(trading_dates)\n",
    "    tdf = pd.DataFrame({'trading_date':trading_dates})\n",
    "    tdf['month'] = tdf['trading_date'].astype(int)//100\n",
    "    \n",
    "    tdfm = tdf.groupby('month')['trading_date'].min().reset_index()\n",
    "\n",
    "    funda_df = fakm_final.join(tdfm.set_index('month'),on='month',how='left')\n",
    "    funda_df = funda_df.rename(columns={'tradedate':'tradedate_fake','trading_date':'tradedate'})\n",
    "    print(funda_df['tradedate'].shape, funda_df[['tradedate']].dropna().shape)\n",
    "    print(funda_df[funda_df['tradedate'].isna()])\n",
    "    #funda_df['tradedate'] = funda_df['tradedate'].astype(int)\n",
    "    stocks_df['tradedate'] = stocks_df['datadate'].astype(int)\n",
    "    stocks_df['tradedate_price'] = stocks_df['Adj Close']\n",
    "    \n",
    "    fa_quarter_prices = funda_df.join(stocks_df[['tradedate','tradedate_price','tic']].set_index(['tradedate','tic']),\n",
    "                                      on=['tradedate','tic'],how='left').dropna()\n",
    "\n",
    "    fa_quarter_prices['next_trading_month'] = fa_quarter_prices['tradedate'].apply(lambda x: dt.datetime.strptime(str(int(x)), '%Y%m%d')).apply(get_trade_month)\n",
    "    fa_prices_df = fa_quarter_prices.join(tdfm.rename(columns={'month':'next_trading_month',\n",
    "                                                                'trading_date':'next_trading_date'}).set_index('next_trading_month'),\n",
    "                                                                  on='next_trading_month',how='left')\n",
    "\n",
    "    fa_prices_df['next_trading_date'] = fa_prices_df['next_trading_date'].apply(lambda x: int(x) if x and ~np.isnan(x) else None)\n",
    "    \n",
    "    stocks_df['next_trading_date'] = stocks_df['datadate'].astype(int)\n",
    "    stocks_df['next_trading_date_price'] = stocks_df['Adj Close']\n",
    "    all_quartly_prices = fa_prices_df.join(stocks_df[['next_trading_date','next_trading_date_price','tic']].set_index(['next_trading_date','tic']),\n",
    "                                      on=['next_trading_date','tic'],how='left')\n",
    "    all_quartly_prices['y_return'] = np.log(all_quartly_prices['next_trading_date_price']/all_quartly_prices['tradedate_price'])\n",
    "\n",
    "    \n",
    "    fundamental_all = pd.merge(all_quartly_prices,sector_tic[['GICS Sector','tic']], on='tic',how='left')\n",
    "    sector_list = fundamental_all['GICS Sector'].unique().tolist()\n",
    "    \n",
    "    sector_map = {}\n",
    "    for i in range(len(sector_list)):\n",
    "        sector_map[sector_list[i]] = i*5+10\n",
    "        \n",
    "    fundamental_all['GICS Sector'] = fundamental_all['GICS Sector'].astype(str)\n",
    "    fundamental_all['gsector'] = fundamental_all['GICS Sector'].apply(lambda x: -1 if x not in sector_map else sector_map[x])\n",
    "    #del sp500_fundamental_final['GICS Sector']\n",
    "    print(fundamental_all.tail())\n",
    "    \n",
    "    fundamental_clean_table = fundamental_all\n",
    "    max_trade_date = fundamental_clean_table.tradedate.max()\n",
    "    keep = fundamental_clean_table[(fundamental_clean_table.tradedate == max_trade_date)]\n",
    "    keep = keep.append(fundamental_clean_table[(fundamental_clean_table.tradedate < max_trade_date)].dropna(subset=['y_return']+fc))\n",
    "    keep['tradedate'] = keep['tradedate'].astype(int)\n",
    "    max_trade_date = keep.tradedate.max()\n",
    "    final_file = final_file_prefix + f'_{max_trade_date}.csv'\n",
    "    keep.to_csv(final_file,index=False)\n",
    "    keep.to_csv(final_file_prefix+'.csv',index=False)\n",
    "    return keep     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a847b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_indices = ['dow30','sp500']\n",
    "idx = 'dow30'\n",
    "km_file, fa_file, stock_file = f\"raw-data/{idx}_km_df.csv\", f\"raw-data/{idx}_fa_df.csv\", f\"raw-data/{idx}_stock_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7c05c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_df = get_tics_key_metrics(km_file,tic_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47523416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f2e37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_df = get_tics_incom_states(fa_file,tic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4149c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df = get_stocks_data(stock_file,tic_list,lookback_days=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d575fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c959b40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tianlong/Downloads/Dynamic-Stock-Recommendation_final_folder'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c1a0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_tic = pd.read_csv('sector_tic.csv')\n",
    "gvkey_conm = pd.read_csv('conm_tic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e74df5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          A\n",
       "1         AA\n",
       "2       AAIC\n",
       "3        AAL\n",
       "4        AAN\n",
       "        ... \n",
       "2954     ZTS\n",
       "2955    ZUMZ\n",
       "2956     ZUO\n",
       "2957    ZYXI\n",
       "2958    TRUE\n",
       "Name: tic, Length: 2959, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gvkey_conm['conm'] = gvkey_conm['conm'].astype(str)\n",
    "gvkey_conm['tic'] = gvkey_conm['tic'].astype(str)\n",
    "gvkey_conm.tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b41ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in gvkey_conm.iterrows():\n",
    "    if not type(row.tic) == 'str' or not :\n",
    "        type(row.tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43a8fd04",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3a520e52912d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfundamental\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessing_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkm_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfa_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstock_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msector_tic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgvkey_conm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'russell3k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-08b3a008684a>\u001b[0m in \u001b[0;36mprocessing_raw_data\u001b[0;34m(km_df, fa_df, stocks_df, sector_tic, gvkey_conm_unique, final_file_prefix)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mdf_gvkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgvkey_conm_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     fakm_final = df_gvkey[['tic','datadate','tradedate','fyearq','fqtr','conm','datacqtr','datafqtr',\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8108\u001b[0m         \u001b[0;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8109\u001b[0m         \"\"\"\n\u001b[0;32m-> 8110\u001b[0;31m         return self._join_compat(\n\u001b[0m\u001b[1;32m   8111\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8112\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8133\u001b[0m                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8134\u001b[0m                 )\n\u001b[0;32m-> 8135\u001b[0;31m             return merge(\n\u001b[0m\u001b[1;32m   8136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8137\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[0;32m---> 74\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 ):\n\u001b[0;32m-> 1193\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "fundamental = processing_raw_data(km_df,fa_df,stock_df,sector_tic, gvkey_conm,'russell3k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b7270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009f102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631d707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
